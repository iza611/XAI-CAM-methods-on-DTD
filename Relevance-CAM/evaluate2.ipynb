{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import torch \n",
    "import torchvision \n",
    "import quantus\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "import copy\n",
    "import gc\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import torch\n",
    "import torchvision\n",
    "import quantus\n",
    "import warnings\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import json\n",
    "# sns.set() \n",
    "\n",
    "# Enable GPU. \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load x_batch and y_batch\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "data_dir = '../data'\n",
    "image_test_dataset = datasets.ImageFolder(os.path.join(data_dir, 'dump_test'), transform)\n",
    "dataloader = torch.utils.data.DataLoader(image_test_dataset, batch_size=1)\n",
    "test_dataset_size = len(image_test_dataset)\n",
    "\n",
    "x_batch = torch.empty(0, 3, 224, 224, dtype=torch.float32)\n",
    "y_batch = torch.empty(0, dtype=torch.uint8)\n",
    "\n",
    "for data in dataloader:\n",
    "    image, label = data\n",
    "    x_batch = torch.cat([x_batch, image], dim=0)\n",
    "    y_batch = torch.cat([y_batch, label], dim=0)\n",
    "\n",
    "x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "x_batch, y_batch = x_batch.cpu().numpy(), y_batch.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.resnet50()\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "model.load_state_dict(torch.load('../data/dtd_state_dict'))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load explanations.\n",
    "layer = 4\n",
    "explanations = {\n",
    "    \"Grad_CAM\": [],\n",
    "    \"Grad_CAM++\": [],\n",
    "    \"Score_CAM\": [],\n",
    "    \"Relevance_CAM\": [],\n",
    "}\n",
    "for method, batch in explanations.items():\n",
    "    dir = f'data/R_CAM_results_layer{layer}/np/heatmaps/{method}/'\n",
    "    files = os.listdir(dir)\n",
    "    for f in files:\n",
    "        file_np = np.load(dir+f)\n",
    "        batch.append(file_np)\n",
    "\n",
    "explanations = {k: np.array(v) for k, v in explanations.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Multi_CAM import get_CAM\n",
    "from tqdm import tqdm\n",
    "\n",
    "def explainer_wrapper(**kwargs):\n",
    "    \"\"\"Wrapper for explainer functions.\"\"\"\n",
    "    inputs = kwargs[\"inputs\"]\n",
    "    targets = kwargs[\"targets\"]\n",
    "    method = kwargs[\"method\"]\n",
    "    layer = kwargs[\"layer\"]\n",
    "    type = kwargs[\"type\"]\n",
    "    size = inputs.shape[0]\n",
    "    # print(f\"inside explainer_wrapper;\\nsize={size};\\ninputs={inputs.shape}\\n{inputs}\\ntargets={targets.shape}\\n{targets}\")\n",
    "    \n",
    "    if(method==\"Grad_CAM++\"): method = \"Grad_CAMpp\"\n",
    "\n",
    "    if(size>1):\n",
    "        all_CAMS = []\n",
    "        for s in tqdm(range(size)):\n",
    "            input = inputs[s]\n",
    "            target = targets[s]\n",
    "            s_CAM = get_CAM(method=method, layer=layer, input=input, target=target)\n",
    "            all_CAMS.append(s_CAM)\n",
    "\n",
    "        return torch.tensor(all_CAMS)\n",
    "\n",
    "    elif(size==1):\n",
    "        input = inputs[0]\n",
    "        target = targets\n",
    "        # print(f\"input={input.shape}\\ntarget={target}\")\n",
    "        s_CAM = get_CAM(method=method, layer=layer, input=input, target=target)\n",
    "        s_CAM = np.reshape(s_CAM, (1, 224, 224))\n",
    "        # print(f\"input={input.shape}, {type(input)}\\ns_CAM={s_CAM.shape}, {type(s_CAM)}\")\n",
    "\n",
    "        if(type==\"tensor\"):\n",
    "            return torch.tensor(s_CAM)    \n",
    "        elif(type==\"numpy\"):\n",
    "            return s_CAM    \n",
    "        \n",
    "        return \"wrong type\"\n",
    "\n",
    "    else:\n",
    "        error_msg = \"wrong inputs shape\"\n",
    "        return error_msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = {\n",
    "    \"Grad_CAM\": [],\n",
    "    \"Grad_CAM++\": [],\n",
    "    \"Score_CAM\": [],\n",
    "    \"Relevance_CAM\": [],\n",
    "}\n",
    "for method, batch in explanations.items():\n",
    "    dir = f'data/R_CAM_results_layer{layer}/np/heatmaps/{method}/'\n",
    "    files = os.listdir(dir)\n",
    "    for f in files:\n",
    "        file_np = np.load(dir+f)\n",
    "        batch.append(file_np)\n",
    "\n",
    "explanations = {k: np.array(v) for k, v in explanations.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Grad_CAM': {}, 'Grad_CAM++': {}, 'Score_CAM': {}, 'Relevance_CAM': {}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if(os.path.exists(\"data/results.npy\")):\n",
    "    with open('data/results.json', 'r') as f:\n",
    "        results = json.load(f)\n",
    "else:\n",
    "    xai_methods = list(explanations.keys())\n",
    "    results = {method : {} for method in xai_methods}\n",
    "\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE:\n",
    "Due to the computational demands of this task, I calculated the results for each method and metric separately by uncommenting the appropriate section and changing the 'method' variable. After the calculations were complete, I saved the results in /data/results.json and then restarted the kernel to move on to the next metric/method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [10:47<00:00,  3.16it/s]\n",
      "100%|██████████| 2048/2048 [11:25<00:00,  2.99it/s]\n",
      "100%|██████████| 2048/2048 [10:24<00:00,  3.28it/s]\n",
      "100%|██████████| 2048/2048 [11:47<00:00,  2.89it/s]\n",
      "100%|██████████| 2048/2048 [11:59<00:00,  2.85it/s]\n",
      "100%|██████████| 2048/2048 [11:41<00:00,  2.92it/s]\n",
      "100%|██████████| 2048/2048 [10:39<00:00,  3.20it/s]\n",
      "100%|██████████| 2048/2048 [12:10<00:00,  2.80it/s]\n",
      "100%|██████████| 2048/2048 [11:24<00:00,  2.99it/s]\n",
      "100%|██████████| 2048/2048 [11:14<00:00,  3.04it/s]\n",
      "100%|██████████| 10/10 [1:54:05<00:00, 684.50s/it]\n",
      "100%|██████████| 2048/2048 [10:44<00:00,  3.18it/s]\n",
      "100%|██████████| 2048/2048 [10:34<00:00,  3.23it/s]\n",
      "100%|██████████| 2048/2048 [11:06<00:00,  3.07it/s]\n",
      "100%|██████████| 2048/2048 [11:07<00:00,  3.07it/s]\n",
      "100%|██████████| 2048/2048 [10:43<00:00,  3.18it/s]\n",
      "100%|██████████| 2048/2048 [10:53<00:00,  3.13it/s]\n",
      "100%|██████████| 2048/2048 [11:07<00:00,  3.07it/s]\n",
      "100%|██████████| 2048/2048 [11:28<00:00,  2.97it/s]\n",
      "100%|██████████| 2048/2048 [10:39<00:00,  3.20it/s]\n",
      "100%|██████████| 2048/2048 [10:48<00:00,  3.16it/s]\n",
      "100%|██████████| 2048/2048 [10:38<00:00,  3.21it/s]\n",
      "100%|██████████| 2048/2048 [10:37<00:00,  3.21it/s]\n",
      "100%|██████████| 2048/2048 [10:38<00:00,  3.21it/s]\n",
      "100%|██████████| 2048/2048 [10:27<00:00,  3.26it/s]\n",
      " 28%|██▊       | 565/2048 [03:02<07:57,  3.10it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 20\u001b[0m\n\u001b[0;32m      2\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mScore_CAM\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[39m# results[method][\"Faithfulness\"] = quantus.RegionPerturbation(\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m#     patch_size=14,\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m#     regions_evaluation=10,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m# explain_func=explainer_wrapper, \u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m# explain_func_kwargs={\"method\":method,\"layer\": layer, \"type\":\"tensor\"})\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m r \u001b[39m=\u001b[39m quantus\u001b[39m.\u001b[39;49mContinuity(\n\u001b[0;32m     21\u001b[0m     patch_size\u001b[39m=\u001b[39;49m\u001b[39m56\u001b[39;49m,\n\u001b[0;32m     22\u001b[0m     nr_steps\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[0;32m     23\u001b[0m     perturb_baseline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39muniform\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     24\u001b[0m     similarity_func\u001b[39m=\u001b[39;49mquantus\u001b[39m.\u001b[39;49msimilarity_func\u001b[39m.\u001b[39;49mcorrelation_spearman,\n\u001b[0;32m     25\u001b[0m     aggregate_func\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mmean,\n\u001b[0;32m     26\u001b[0m     return_aggregate\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     27\u001b[0m     disable_warnings\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     28\u001b[0m )(model\u001b[39m=\u001b[39;49mmodel, \n\u001b[0;32m     29\u001b[0m    x_batch\u001b[39m=\u001b[39;49mx_batch,\n\u001b[0;32m     30\u001b[0m    y_batch\u001b[39m=\u001b[39;49my_batch,\n\u001b[0;32m     31\u001b[0m    a_batch\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,    \n\u001b[0;32m     32\u001b[0m    device\u001b[39m=\u001b[39;49mdevice,\n\u001b[0;32m     33\u001b[0m    explain_func\u001b[39m=\u001b[39;49mexplainer_wrapper, \n\u001b[0;32m     34\u001b[0m    explain_func_kwargs\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mmethod\u001b[39;49m\u001b[39m\"\u001b[39;49m:method,\u001b[39m\"\u001b[39;49m\u001b[39mlayer\u001b[39;49m\u001b[39m\"\u001b[39;49m: layer, \u001b[39m\"\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39mtensor\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n\u001b[0;32m     36\u001b[0m global_avg \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     37\u001b[0m n_patches \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(r)\n",
      "File \u001b[1;32mc:\\Users\\Surface\\.conda\\envs\\new\\lib\\site-packages\\quantus\\metrics\\robustness\\continuity.py:252\u001b[0m, in \u001b[0;36mContinuity.__call__\u001b[1;34m(self, model, x_batch, y_batch, a_batch, s_batch, channel_first, explain_func, explain_func_kwargs, model_predict_kwargs, softmax, device, batch_size, custom_batch, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[0;32m    163\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    164\u001b[0m     model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    178\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[0;32m    179\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[39m    This implementation represents the main logic of the metric and makes the class object callable.\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[39m    It completes instance-wise evaluation of explanations (a_batch) with respect to input data (x_batch),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39m        >> scores = metric(model=model, x_batch=x_batch, y_batch=y_batch, a_batch=a_batch_saliency}\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 252\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\n\u001b[0;32m    253\u001b[0m         model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m    254\u001b[0m         x_batch\u001b[39m=\u001b[39mx_batch,\n\u001b[0;32m    255\u001b[0m         y_batch\u001b[39m=\u001b[39my_batch,\n\u001b[0;32m    256\u001b[0m         a_batch\u001b[39m=\u001b[39ma_batch,\n\u001b[0;32m    257\u001b[0m         s_batch\u001b[39m=\u001b[39ms_batch,\n\u001b[0;32m    258\u001b[0m         custom_batch\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    259\u001b[0m         channel_first\u001b[39m=\u001b[39mchannel_first,\n\u001b[0;32m    260\u001b[0m         explain_func\u001b[39m=\u001b[39mexplain_func,\n\u001b[0;32m    261\u001b[0m         explain_func_kwargs\u001b[39m=\u001b[39mexplain_func_kwargs,\n\u001b[0;32m    262\u001b[0m         softmax\u001b[39m=\u001b[39msoftmax,\n\u001b[0;32m    263\u001b[0m         device\u001b[39m=\u001b[39mdevice,\n\u001b[0;32m    264\u001b[0m         model_predict_kwargs\u001b[39m=\u001b[39mmodel_predict_kwargs,\n\u001b[0;32m    265\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    266\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Surface\\.conda\\envs\\new\\lib\\site-packages\\quantus\\metrics\\base.py:225\u001b[0m, in \u001b[0;36mMetric.__call__\u001b[1;34m(self, model, x_batch, y_batch, a_batch, s_batch, channel_first, explain_func, explain_func_kwargs, model_predict_kwargs, softmax, device, batch_size, custom_batch, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m iterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_instance_iterator(data\u001b[39m=\u001b[39mdata)\n\u001b[0;32m    224\u001b[0m \u001b[39mfor\u001b[39;00m id_instance, data_instance \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m--> 225\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate_instance(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdata_instance)\n\u001b[0;32m    226\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_results[id_instance] \u001b[39m=\u001b[39m result\n\u001b[0;32m    228\u001b[0m \u001b[39m# Call custom post-processing.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Surface\\.conda\\envs\\new\\lib\\site-packages\\quantus\\metrics\\robustness\\continuity.py:320\u001b[0m, in \u001b[0;36mContinuity.evaluate_instance\u001b[1;34m(self, model, x, y, a, s)\u001b[0m\n\u001b[0;32m    312\u001b[0m prediction_changed \u001b[39m=\u001b[39m (\n\u001b[0;32m    313\u001b[0m     model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39mexpand_dims(x, \u001b[39m0\u001b[39m))\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    314\u001b[0m     \u001b[39m!=\u001b[39m model\u001b[39m.\u001b[39mpredict(x_input)\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    315\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_nan_when_prediction_changes\n\u001b[0;32m    316\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    317\u001b[0m )\n\u001b[0;32m    319\u001b[0m \u001b[39m# Generate explanations on perturbed input.\u001b[39;00m\n\u001b[1;32m--> 320\u001b[0m a_perturbed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplain_func(\n\u001b[0;32m    321\u001b[0m     model\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mget_model(),\n\u001b[0;32m    322\u001b[0m     inputs\u001b[39m=\u001b[39mx_input,\n\u001b[0;32m    323\u001b[0m     targets\u001b[39m=\u001b[39my,\n\u001b[0;32m    324\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplain_func_kwargs,\n\u001b[0;32m    325\u001b[0m )\n\u001b[0;32m    326\u001b[0m \u001b[39m# Taking the first element, since a_perturbed will be expanded to a batch dimension\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[39m# not expected by the current index management functions.\u001b[39;00m\n\u001b[0;32m    328\u001b[0m a_perturbed \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mexpand_attribution_channel(a_perturbed, x_input)[\u001b[39m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[6], line 30\u001b[0m, in \u001b[0;36mexplainer_wrapper\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m target \u001b[39m=\u001b[39m targets\n\u001b[0;32m     29\u001b[0m \u001b[39m# print(f\"input={input.shape}\\ntarget={target}\")\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m s_CAM \u001b[39m=\u001b[39m get_CAM(method\u001b[39m=\u001b[39;49mmethod, layer\u001b[39m=\u001b[39;49mlayer, \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39minput\u001b[39;49m, target\u001b[39m=\u001b[39;49mtarget)\n\u001b[0;32m     31\u001b[0m s_CAM \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(s_CAM, (\u001b[39m1\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m))\n\u001b[0;32m     32\u001b[0m \u001b[39m# print(f\"input={input.shape}, {type(input)}\\ns_CAM={s_CAM.shape}, {type(s_CAM)}\")\u001b[39;00m\n",
      "File \u001b[1;32mg:\\Mój dysk\\MSc AI at QMUL\\EC709 Introduction to Computer Vision\\courseworks\\CW2\\coding\\proper_code\\Relevance-CAM\\Multi_CAM.py:161\u001b[0m, in \u001b[0;36mget_CAM\u001b[1;34m(method, layer, input, target, idx, save)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[39mreturn\u001b[39;00m grad_campp\n\u001b[0;32m    159\u001b[0m \u001b[39mif\u001b[39;00m(method\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mScore_CAM\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 161\u001b[0m     score_map, _ \u001b[39m=\u001b[39m Score_CAM_class(image, class_idx\u001b[39m=\u001b[39;49mmaxindex)\n\u001b[0;32m    162\u001b[0m     score_map \u001b[39m=\u001b[39m score_map\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m    163\u001b[0m     score_map \u001b[39m=\u001b[39m score_map\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mg:\\Mój dysk\\MSc AI at QMUL\\EC709 Introduction to Computer Vision\\courseworks\\CW2\\coding\\proper_code\\Relevance-CAM\\LRP_util.py:135\u001b[0m, in \u001b[0;36mScoreCAM.__call__\u001b[1;34m(self, input, class_idx, retain_graph)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, class_idx\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, retain_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39minput\u001b[39;49m, class_idx, retain_graph)\n",
      "File \u001b[1;32mg:\\Mój dysk\\MSc AI at QMUL\\EC709 Introduction to Computer Vision\\courseworks\\CW2\\coding\\proper_code\\Relevance-CAM\\LRP_util.py:117\u001b[0m, in \u001b[0;36mScoreCAM.forward\u001b[1;34m(self, input, class_idx, retain_graph)\u001b[0m\n\u001b[0;32m    113\u001b[0m norm_saliency_map \u001b[39m=\u001b[39m (saliency_map \u001b[39m-\u001b[39m saliency_map\u001b[39m.\u001b[39mmin()) \u001b[39m/\u001b[39m (saliency_map\u001b[39m.\u001b[39mmax() \u001b[39m-\u001b[39m saliency_map\u001b[39m.\u001b[39mmin())\n\u001b[0;32m    115\u001b[0m \u001b[39m# how much increase if keeping the highlighted region\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[39m# predication on masked input\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39minput\u001b[39;49m \u001b[39m*\u001b[39;49m norm_saliency_map)\n\u001b[0;32m    118\u001b[0m output \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(output, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    119\u001b[0m score \u001b[39m=\u001b[39m output[\u001b[39m0\u001b[39m][predicted_class]\n",
      "File \u001b[1;32mc:\\Users\\Surface\\.conda\\envs\\new\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mg:\\Mój dysk\\MSc AI at QMUL\\EC709 Introduction to Computer Vision\\courseworks\\CW2\\coding\\proper_code\\Relevance-CAM\\modules\\resnet.py:297\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x, mode, target_class)\u001b[0m\n\u001b[0;32m    294\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m    295\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool(x)\n\u001b[1;32m--> 297\u001b[0m layer1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer1(x)\n\u001b[0;32m    298\u001b[0m layer2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(layer1)\n\u001b[0;32m    299\u001b[0m layer3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer3(layer2)\n",
      "File \u001b[1;32mc:\\Users\\Surface\\.conda\\envs\\new\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Surface\\.conda\\envs\\new\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Surface\\.conda\\envs\\new\\lib\\site-packages\\torch\\nn\\modules\\module.py:1148\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks)\n\u001b[0;32m   1146\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[1;32m-> 1148\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1149\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1150\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n",
      "File \u001b[1;32mg:\\Mój dysk\\MSc AI at QMUL\\EC709 Introduction to Computer Vision\\courseworks\\CW2\\coding\\proper_code\\Relevance-CAM\\modules\\resnet.py:158\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39m# out = self.add([out, x2])\u001b[39;00m\n\u001b[0;32m    157\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd([out, x])\n\u001b[1;32m--> 158\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrelu3(out)\n\u001b[0;32m    160\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Surface\\.conda\\envs\\new\\lib\\site-packages\\torch\\nn\\modules\\module.py:1148\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks)\n\u001b[0;32m   1146\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[1;32m-> 1148\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1149\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1150\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n",
      "File \u001b[1;32mc:\\Users\\Surface\\.conda\\envs\\new\\lib\\site-packages\\torch\\nn\\modules\\activation.py:98\u001b[0m, in \u001b[0;36mReLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[1;32mc:\\Users\\Surface\\.conda\\envs\\new\\lib\\site-packages\\torch\\nn\\functional.py:1455\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1453\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(relu, (\u001b[39minput\u001b[39m,), \u001b[39minput\u001b[39m, inplace\u001b[39m=\u001b[39minplace)\n\u001b[0;32m   1454\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m-> 1455\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu_(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m   1456\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1457\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39minput\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# available methods: 'Grad_CAM' 'Grad_CAM++' 'Score_CAM' 'Relevance_CAM'\n",
    "method = \"Score_CAM\"\n",
    "\n",
    "# results[method][\"Faithfulness\"] = quantus.RegionPerturbation(\n",
    "#     patch_size=14,\n",
    "#     regions_evaluation=10,\n",
    "#     perturb_baseline=\"uniform\",  \n",
    "#     normalise=True,\n",
    "#     aggregate_func=np.mean,\n",
    "#     return_aggregate=True,\n",
    "#     disable_warnings=True,\n",
    "# )(model=model,\n",
    "# x_batch=x_batch,\n",
    "# y_batch=y_batch,\n",
    "# a_batch=None,\n",
    "# device=device,\n",
    "# explain_func=explainer_wrapper, \n",
    "# explain_func_kwargs={\"method\":method,\"layer\": layer, \"type\":\"tensor\"})\n",
    "\n",
    "r = quantus.Continuity(\n",
    "    patch_size=56,\n",
    "    nr_steps=5,\n",
    "    perturb_baseline=\"uniform\",\n",
    "    similarity_func=quantus.similarity_func.correlation_spearman,\n",
    "    aggregate_func=np.mean,\n",
    "    return_aggregate=True,\n",
    "    disable_warnings=True,\n",
    ")(model=model, \n",
    "   x_batch=x_batch,\n",
    "   y_batch=y_batch,\n",
    "   a_batch=None,    \n",
    "   device=device,\n",
    "   explain_func=explainer_wrapper, \n",
    "   explain_func_kwargs={\"method\":method,\"layer\": layer, \"type\":\"tensor\"})\n",
    "\n",
    "global_avg = 0\n",
    "n_patches = len(r)\n",
    "r = r[0]\n",
    "for patch in r:\n",
    "    avg = np.mean(np.array(r[patch]))\n",
    "    global_avg += avg\n",
    "global_avg = global_avg/n_patches\n",
    "results[method][\"Robustness\"] = [global_avg]\n",
    "\n",
    "# results[method][\"Axiomatic\"] = quantus.NonSensitivity(\n",
    "#     abs=True,\n",
    "#     eps=1e-5,\n",
    "#     n_samples=5, \n",
    "#     perturb_baseline=\"black\",\n",
    "#     perturb_func=quantus.perturb_func.baseline_replacement_by_indices,\n",
    "#     features_in_step=6272,\n",
    "#     aggregate_func=np.mean,\n",
    "#     return_aggregate=True,\n",
    "#     disable_warnings=True,\n",
    "# )(model=model, \n",
    "#    x_batch=x_batch,\n",
    "#    y_batch=y_batch,\n",
    "#    a_batch=None,    \n",
    "#    device=device,\n",
    "#    explain_func=explainer_wrapper, \n",
    "#    explain_func_kwargs={\"method\":method,\"layer\": layer, \"type\":\"tensor\"})\n",
    "\n",
    "# results[method][\"Complexity\"] = quantus.Complexity(\n",
    "#     aggregate_func=np.mean,\n",
    "#     return_aggregate=True,\n",
    "#     disable_warnings=True,\n",
    "# )(model=model, \n",
    "#    x_batch=x_batch,\n",
    "#    y_batch=y_batch,\n",
    "#    a_batch=None,    \n",
    "#    device=device,\n",
    "#    explain_func=explainer_wrapper, \n",
    "#    explain_func_kwargs={\"method\":method,\"layer\": layer, \"type\":\"tensor\"})\n",
    "\n",
    "# results[method][\"Randomisation\"] = quantus.RandomLogit(\n",
    "#     num_classes=10,\n",
    "#     similarity_func=quantus.similarity_func.ssim,\n",
    "#     aggregate_func=np.mean,\n",
    "#     return_aggregate=True,\n",
    "#     disable_warnings=True,\n",
    "# )(model=model, \n",
    "#    x_batch=x_batch,\n",
    "#    y_batch=y_batch,\n",
    "#    a_batch=None,    \n",
    "#    device=device,\n",
    "#    explain_func=explainer_wrapper, \n",
    "#    explain_func_kwargs={\"method\":method,\"layer\": layer, \"type\":\"numpy\"})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/results.json', 'w') as f:\n",
    "  json.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Oct 24 2022, 16:02:16) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d355f4e0125df31603f6986b386f54d29222e1d3c7b6baa68bf52f21b35fd0be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
